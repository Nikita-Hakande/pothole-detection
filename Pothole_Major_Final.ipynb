{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Pothole Detection"
      ],
      "metadata": {
        "id": "HTn7oiZU-3RX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Extract Dataset"
      ],
      "metadata": {
        "id": "-N0ZWB8y-15e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zip_path = \"/content/PotholeDataset.zip\"\n",
        "extract_path = \"/content/Pothole_Data\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"Extracted to:\", extract_path)\n"
      ],
      "metadata": {
        "id": "xc4SS-kLrNIV",
        "outputId": "30666bbe-6fd5-4aa1-b0d1-3cbbd4752b9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "BadZipFile",
          "evalue": "File is not a zip file",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1183879179.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mextract_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/Pothole_Data\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/zipfile/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[1;32m   1368\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RealGetContents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m                 \u001b[0;31m# set the modified flag so central directory gets written\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/zipfile/__init__.py\u001b[0m in \u001b[0;36m_RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1435\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1436\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mendrec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1437\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1438\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1439\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBadZipFile\u001b[0m: File is not a zip file"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import Libraries"
      ],
      "metadata": {
        "id": "V1RlcFmq-9xJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import glob\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "6-q0pMptrNFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load Dataset"
      ],
      "metadata": {
        "id": "oOVZL_Vh_Dcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "size = 150   # image size\n",
        "\n",
        "def load_images(path):\n",
        "    images = []\n",
        "    files = glob.glob(path + \"/*\")\n",
        "    for f in files:\n",
        "        img = cv2.imread(f, 0)\n",
        "        img = cv2.resize(img, (size, size))\n",
        "        images.append(img)\n",
        "    return np.asarray(images)\n"
      ],
      "metadata": {
        "id": "9AKY9FHUrNDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load images"
      ],
      "metadata": {
        "id": "TkeTHfhG_HGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_pothole = load_images(\"/content/Pothole_Data/PotholeDataset/train/Pothole\")\n",
        "train_plain   = load_images(\"/content/Pothole_Data/PotholeDataset/train/Plain\")\n",
        "\n",
        "test_pothole  = load_images(\"/content/Pothole_Data/PotholeDataset/test/Pothole\")\n",
        "test_plain    = load_images(\"/content/Pothole_Data/PotholeDataset/test/Plain\")"
      ],
      "metadata": {
        "id": "0gOCjYm0rM_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Prepare Training + Test Sets"
      ],
      "metadata": {
        "id": "gtkVZsDS_NFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.concatenate([train_pothole, train_plain])\n",
        "X_test  = np.concatenate([test_pothole, test_plain])\n",
        "\n",
        "y_train = np.concatenate([\n",
        "    np.ones(len(train_pothole)),  # pothole = 1\n",
        "    np.zeros(len(train_plain))    # plain = 0\n",
        "])\n",
        "\n",
        "y_test = np.concatenate([\n",
        "    np.ones(len(test_pothole)),\n",
        "    np.zeros(len(test_plain))\n",
        "])\n",
        "\n",
        "X_train, y_train = shuffle(X_train, y_train)\n",
        "X_test, y_test = shuffle(X_test, y_test)\n",
        "\n",
        "X_train = X_train.reshape(-1, size, size, 1) / 255.0\n",
        "X_test  = X_test.reshape(-1, size, size, 1) / 255.0\n",
        "\n",
        "y_train = to_categorical(y_train, 2)\n",
        "y_test  = to_categorical(y_test, 2)\n",
        "\n",
        "print(\"Train:\", X_train.shape)\n",
        "print(\"Test:\",  X_test.shape)\n"
      ],
      "metadata": {
        "id": "bR8jXdKorUu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Augmentation"
      ],
      "metadata": {
        "id": "ASeMxpgE_R0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "datagen.fit(X_train)\n"
      ],
      "metadata": {
        "id": "lwFHb_hbrWDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Build Strong CNN Model"
      ],
      "metadata": {
        "id": "V7kuM8Kc_U2t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(32,(3,3),activation=\"relu\",padding=\"same\",input_shape=(150,150,1)))\n",
        "    model.add(MaxPooling2D(2,2))\n",
        "\n",
        "    model.add(Conv2D(64,(3,3),activation=\"relu\",padding=\"same\"))\n",
        "    model.add(MaxPooling2D(2,2))\n",
        "\n",
        "    model.add(Conv2D(128,(3,3),activation=\"relu\",padding=\"same\"))\n",
        "    model.add(MaxPooling2D(2,2))\n",
        "\n",
        "    model.add(Conv2D(256,(3,3),activation=\"relu\",padding=\"same\"))\n",
        "    model.add(MaxPooling2D(2,2))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256, activation=\"relu\"))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Dense(2, activation=\"softmax\"))\n",
        "    return model\n",
        "\n",
        "model = build_model()\n",
        "model.compile(optimizer=Adam(0.0004), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "2r5B1VTQrXXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train-Validation Split"
      ],
      "metadata": {
        "id": "NrIsd21-_ZLL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train2, X_val, y_train2, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.2, shuffle=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "h-GglD12rY5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TRAIN THE MODEL"
      ],
      "metadata": {
        "id": "nef2yBAV_blZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    datagen.flow(X_train2, y_train2, batch_size=32),\n",
        "    epochs=30,\n",
        "    validation_data=(X_val, y_val)\n",
        ")\n"
      ],
      "metadata": {
        "id": "2va-yrxVraOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluate on Test Set"
      ],
      "metadata": {
        "id": "mdlr35Bw_ees"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = model.evaluate(X_test, y_test)\n",
        "print(\"Test Accuracy:\", acc * 100, \"%\")"
      ],
      "metadata": {
        "id": "kPpSv15travj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Save Model"
      ],
      "metadata": {
        "id": "3loqhjbI_hiU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"pothole_cnn_model.h5\")\n",
        "print(\"Model saved as pothole_cnn_model.h5\")"
      ],
      "metadata": {
        "id": "aJdeKsdprcSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Confusion Matrix + Classification Report"
      ],
      "metadata": {
        "id": "Ks9Aav7VJP4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "y_true_labels = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_true_labels, y_pred_labels)\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Plain','Pothole'],\n",
        "            yticklabels=['Plain','Pothole'])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(y_true_labels, y_pred_labels, target_names=['Plain','Pothole']))"
      ],
      "metadata": {
        "id": "i-HABE7wJPiT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "aec8a9f3-5aa1-45b2-d2c1-10c1b5aa9e1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4052474173.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0my_pred_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0my_true_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Accuracy & Loss Graph"
      ],
      "metadata": {
        "id": "7uXnRmGjJUrA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "\n",
        "# Accuracy graph\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
        "plt.title('Accuracy Over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Loss graph\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "plt.title('Loss Over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PM9WrsiVJXBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Real-time Image Prediction With Parameters"
      ],
      "metadata": {
        "id": "nhEpDgw6APnW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Load your CNN model\n",
        "model = load_model(\"pothole_cnn_model.h5\")\n",
        "size = 150\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# AREA & DEPTH CALCULATION\n",
        "# ---------------------------\n",
        "def calculate_area_depth(gray_img):\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "        area (0.0 to 1.0)\n",
        "        depth (0.0 to 1.0)\n",
        "    \"\"\"\n",
        "\n",
        "    # Threshold to isolate dark pothole-like regions\n",
        "    _, th = cv2.threshold(gray_img, 120, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "    total_pixels = gray_img.size\n",
        "    dark_pixels = np.sum(th == 255)\n",
        "\n",
        "    # AREA ESTIMATE (ratio)\n",
        "    area_ratio = dark_pixels / total_pixels\n",
        "\n",
        "    # DEPTH ESTIMATE (inverse brightness of dark regions)\n",
        "    if dark_pixels == 0:\n",
        "        depth_ratio = 0\n",
        "    else:\n",
        "        dark_region = gray_img[th == 255]\n",
        "        avg_dark = np.mean(dark_region)\n",
        "        depth_ratio = 1 - (avg_dark / 255)   # 0 (bright) → 1 (dark)\n",
        "\n",
        "    return round(area_ratio, 3), round(depth_ratio, 3)\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# PROBABILITY LOGIC\n",
        "# ---------------------------\n",
        "def evaluate_pothole(area, depth):\n",
        "    \"\"\"\n",
        "    Decide pothole severity based on area & depth.\n",
        "    \"\"\"\n",
        "\n",
        "    # If nothing detected → plain road\n",
        "    if area == 0 or depth == 0:\n",
        "        probability = 0\n",
        "        message = \"✔ Plain road — safe to drive.\"\n",
        "        return probability, message\n",
        "\n",
        "    # Probability formula\n",
        "    probability = (area * 0.6 + depth * 0.4) * 100\n",
        "    probability = round(probability, 2)\n",
        "\n",
        "    # Decision\n",
        "    if probability >= 50:\n",
        "        message = \"❗ Reduce speed immediately — major pothole detected.\"\n",
        "    else:\n",
        "        message = \"⚠ Drive slow — mild pothole ahead.\"\n",
        "\n",
        "    return probability, message\n",
        "\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# MAIN PREDICTION FUNCTION\n",
        "# ---------------------------\n",
        "def predict_image(image_path):\n",
        "\n",
        "    img_color = cv2.imread(image_path)\n",
        "    if img_color is None:\n",
        "        print(\"❌ ERROR: Image not found.\")\n",
        "        return\n",
        "\n",
        "    img_gray = cv2.cvtColor(img_color, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # CNN classification\n",
        "    resized = cv2.resize(img_gray, (size, size))\n",
        "    cnn_input = resized.reshape(1, size, size, 1) / 255.0\n",
        "    pred = model.predict(cnn_input)\n",
        "\n",
        "    class_id = np.argmax(pred)\n",
        "    confidence = float(np.max(pred))\n",
        "\n",
        "    label = \"normal\" if class_id == 0 else \"pothole\"\n",
        "\n",
        "\n",
        "    # ----------------------------------------------------------\n",
        "    # ✔ FIXED: If CNN predicts NORMAL → IGNORE AREA + DEPTH\n",
        "    # ----------------------------------------------------------\n",
        "    if label == \"normal\":\n",
        "        print(\"\\n=======================\")\n",
        "        print(\"      IMAGE PREVIEW\")\n",
        "        print(\"=======================\\n\")\n",
        "        cv2_imshow(img_color)\n",
        "\n",
        "        print(\"\\n=======================\")\n",
        "        print(\"      RESULT\")\n",
        "        print(\"=======================\\n\")\n",
        "\n",
        "        print(\"Prediction: NORMAL\")\n",
        "        print(f\"CNN Confidence: {round(confidence * 100, 2)} %\")\n",
        "        print(\"Estimated Area: 0.0\")\n",
        "        print(\"Estimated Depth: 0.0\")\n",
        "        print(\"Probability: 0 %\")\n",
        "        print(\"\\nMessage: ✔ Normal road — you can drive normally.\")\n",
        "        print(\"\\n=======================\\n\")\n",
        "        return\n",
        "    # ----------------------------------------------------------\n",
        "\n",
        "\n",
        "    # For POTHOLE → calculate area & depth\n",
        "    area, depth = calculate_area_depth(img_gray)\n",
        "    probability, message = evaluate_pothole(area, depth)\n",
        "\n",
        "    # ----- OUTPUT -----\n",
        "    print(\"\\n=======================\")\n",
        "    print(\"      IMAGE PREVIEW\")\n",
        "    print(\"=======================\\n\")\n",
        "    cv2_imshow(img_color)\n",
        "\n",
        "    print(\"\\n=======================\")\n",
        "    print(\"      RESULT\")\n",
        "    print(\"=======================\\n\")\n",
        "\n",
        "    print(f\"Prediction: POTHOLE\")\n",
        "    print(f\"CNN Confidence: {round(confidence * 100, 2)} %\")\n",
        "    print(f\"Estimated Area: {area}\")\n",
        "    print(f\"Estimated Depth: {depth}\")\n",
        "    print(f\"Probability: {probability} %\")\n",
        "    print(\"\\nMessage:\", message)\n",
        "    print(\"\\n=======================\\n\")"
      ],
      "metadata": {
        "id": "KzSb4kIhrqI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_image(\"/content/Pothole5.jpg\")"
      ],
      "metadata": {
        "id": "aOUT6pLvrrmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_image(\"/content/Pothole6.jpg\")"
      ],
      "metadata": {
        "id": "wnAoC9Av6k5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_image(\"/content/Plain1.jpg\")"
      ],
      "metadata": {
        "id": "CfYzcKFlHXIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model in .keras format\n",
        "model.save(\"pothole_cnn_model.keras\")\n",
        "print(\"Model saved as pothole_cnn_model.keras\")"
      ],
      "metadata": {
        "id": "TzjMO4edxaNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "SewrSpnqxcw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.build((None, 150, 150, 1))   # Ensure new input spec\n",
        "model.save(\"pothole_cnn_model.keras\", save_format=\"keras\")\n",
        "print(\"Model Saved Successfully!\")\n"
      ],
      "metadata": {
        "id": "LhX_HRbCCKnb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}